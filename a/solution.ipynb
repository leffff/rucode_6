{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f88db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\len\\pythonproject1\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from madgrad import MADGRAD, MirrorMADGRAD\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import (\n",
    "    get_constant_schedule,\n",
    "    get_constant_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_polynomial_decay_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef02b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transforms=torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomRotation(45),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.6),\n",
    "    torchvision.transforms.RandomVerticalFlip(p=0.6),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize(size=(256,256)),\n",
    "    torchvision.transforms.Lambda(lambda a: a / 255),\n",
    "    \n",
    "#     torchvision.transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(f\"./data_ext/train\", transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf458c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight, gamma=0, eps=1e-7):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        self.ce = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = self.ce(input, target)\n",
    "        p = torch.exp(-logp)\n",
    "        loss = (1 - p) ** self.gamma * logp\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56fb693",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, backbone, output_dim):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        del backbone.fc\n",
    "        self.backbone.dropout = nn.Dropout(p=0.1)\n",
    "        self.backbone.fc = torch.nn.Linear(in_features=2048, out_features=output_dim, bias=True)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        out = self.backbone(image)\n",
    "#         out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be238d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_function, optimizer, scheduler, device, n_accumulated_grads=0):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    dl_size = len(data_loader)\n",
    "    \n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    batch_i = 0\n",
    "    steps_to_accumulate_grads = 0\n",
    "    for batch in tqdm(data_loader):\n",
    "        image, target = batch\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()        \n",
    "        logits = model(image)\n",
    "        \n",
    "        preds.append(logits.argmax(dim=1))\n",
    "        targets.append(target)\n",
    "                \n",
    "        loss = loss_function(logits, target)\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        if steps_to_accumulate_grads == n_accumulated_grads:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            steps_to_accumulate_grads = 0\n",
    "        else:\n",
    "            steps_to_accumulate_grads += 1\n",
    "            \n",
    "    if steps_to_accumulate_grads != 0:\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    targets = torch.cat(targets, dim=0)\n",
    "    acc = (targets == preds).sum() / preds.shape[0]\n",
    "    f1 = f1_score(preds.cpu(), targets.cpu(), average='macro')\n",
    "    \n",
    "    metrics = {\n",
    "        \"Train Loss\": total_train_loss / dl_size,\n",
    "        \"Train Accuracy\": acc.item(),\n",
    "        \"Train F1\": f1.item()\n",
    "    }\n",
    "    \n",
    "    \n",
    "    return metrics\n",
    "    \n",
    "    \n",
    "def eval_epoch(model, data_loader, loss_function, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    dl_size = len(data_loader)\n",
    "\n",
    "    \n",
    "    for batch in tqdm(data_loader):\n",
    "        image, target = batch\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(image)\n",
    "            preds.append(logits.argmax(dim=1))\n",
    "            targets.append(target)\n",
    "        \n",
    "        loss = loss_function(logits, target)\n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    targets = torch.cat(targets, dim=0)\n",
    "    acc = (targets == preds).sum() / preds.shape[0]\n",
    "    f1 = f1_score(preds.cpu(), targets.cpu(), average='macro')\n",
    "    \n",
    "    metrics = {\n",
    "        \"Eval Loss\": total_train_loss / dl_size,\n",
    "        \"Eval Accuracy\": acc.item(),\n",
    "        \"Eval F1\": f1.item()\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849270f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(project_name,\n",
    "                     model, \n",
    "                     dataset, \n",
    "                     loss_function, \n",
    "                     strat_array=None,\n",
    "                     device=torch.device(\"cuda\"),\n",
    "                     random_state: int=69, \n",
    "                     shuffle: bool=True, \n",
    "                     n_folds: int=4, \n",
    "                     epochs: int=5, \n",
    "                     lr: float=1e-6,\n",
    "                     start_fold: int=0, \n",
    "                     batch_size: int=32,\n",
    "                     iters_to_accumulate=None,\n",
    "                     n_accumulated_grads: int = 0):\n",
    "    random.seed(random_state),\n",
    "    np.random.seed(random_state)\n",
    "    torch.manual_seed(random_state)\n",
    "    torch.cuda.manual_seed_all(random_state)\n",
    "    \n",
    "    loss_function.to(device)\n",
    "    if strat_array:\n",
    "        kfold = StratifiedKFold(n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        split = kfold.split(dataset, strat_array)\n",
    "    else: \n",
    "        kfold = KFold(n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        split = kfold.split(dataset)\n",
    "\n",
    "    for fold, (train_ids, eval_ids) in enumerate(split):\n",
    "        if fold >= start_fold:\n",
    "            print(f'FOLD {fold}')\n",
    "            print('--------------------------------')\n",
    "            \n",
    "            \n",
    "            '''run = wandb.init(\n",
    "                name=f\"fold_{fold}\",\n",
    "                project=f\"{project_name}_fold_{fold}\",\n",
    "                config={ \n",
    "                         \"random_state\": random_state, \n",
    "                         \"shuffle\": shuffle,\n",
    "                         \"epochs\": epochs, \n",
    "                         \"learning_rate\": lr,\n",
    "                         \"batch_size\": batch_size,\n",
    "                         \"iters_to_accumulate\": iters_to_accumulate\n",
    "                        }\n",
    "            )'''\n",
    "\n",
    "            optimizer = MADGRAD(\n",
    "            model.parameters(),\n",
    "            lr = lr, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "        )\n",
    "\n",
    "            train_subsampler = torch.utils.data.Subset(dataset,  train_ids)\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                          train_subsampler, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle)\n",
    "\n",
    "            eval_subsampler = torch.utils.data.Subset(dataset,  eval_ids)\n",
    "            eval_loader = torch.utils.data.DataLoader(\n",
    "                          eval_subsampler,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle)\n",
    "            \n",
    "            total_steps = len(train_loader) * epochs \n",
    "\n",
    "            scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                                    num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                                    num_training_steps = total_steps)\n",
    "\n",
    "            mrrs = []\n",
    "\n",
    "            for epoch_i in range(0, epochs):\n",
    "                train_metrics = train_epoch(model, train_loader, loss_function, optimizer, scheduler, device)\n",
    "                eval_metrics = eval_epoch(model, eval_loader, loss_function, device)\n",
    "                \n",
    "                print(f\"EPOCH: {epoch_i}\")\n",
    "                print(train_metrics)\n",
    "                print(eval_metrics)\n",
    "                \n",
    "                #run.log(train_metrics)\n",
    "                #run.log(eval_metrics)\n",
    "                            \n",
    "            #run.finish()\n",
    "\n",
    "\n",
    "def single_model(model, \n",
    "                     dataset, \n",
    "                     loss_function, \n",
    "                     device=torch.device(\"cuda\"),\n",
    "                     random_state: int=69, \n",
    "                     shuffle=True,\n",
    "                     epochs: int=15, \n",
    "                     lr: float=1e-6,\n",
    "                     batch_size: int=32,\n",
    "                     start_epoch=0\n",
    "                     ):\n",
    "    random.seed(random_state),\n",
    "    np.random.seed(random_state)\n",
    "    torch.manual_seed(random_state)\n",
    "    torch.cuda.manual_seed_all(random_state)\n",
    "    \n",
    "    loss_function.to(device)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = MADGRAD(\n",
    "        model.parameters(),\n",
    "        lr = lr, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "    )\n",
    "    \n",
    "    fold_path = f'saves/resnet'\n",
    "    if not os.path.exists(fold_path):\n",
    "        os.mkdir(fold_path)\n",
    "        \n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "                    dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=shuffle\n",
    "    )\n",
    "    \n",
    "    total_steps = len(data_loader) * epochs \n",
    "\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "        if epoch_i >= start_epoch:\n",
    "            train_metrics = train_epoch(model, data_loader, loss_function, optimizer, scheduler, device)\n",
    "            epoch_path = fold_path+f'/epoch_{epoch_i}'\n",
    "            if not os.path.exists(epoch_path):\n",
    "                os.mkdir(epoch_path)\n",
    "            save_model(model, epoch_path)\n",
    "            print(\"EPOCH\", epoch_i)\n",
    "            print(train_metrics)\n",
    "            # eval_epoch(fold_model, eval_loader, loss_function, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d12ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model, path+'/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153fca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(project_name,\n",
    "                     model, \n",
    "                     dataset, \n",
    "                     loss_function, \n",
    "                     strat_array=None,\n",
    "                     device=torch.device(\"cuda\"),\n",
    "                     random_state: int=69, \n",
    "                     shuffle: bool=True, \n",
    "                     n_folds: int=4, \n",
    "                     epochs: int=5, \n",
    "                     lr: float=1e-6,\n",
    "                     start_fold: int=0, \n",
    "                     batch_size: int=32,\n",
    "                     iters_to_accumulate=None,\n",
    "                     n_accumulated_grads: int = 0):\n",
    "    random.seed(random_state),\n",
    "    np.random.seed(random_state)\n",
    "    torch.manual_seed(random_state)\n",
    "    torch.cuda.manual_seed_all(random_state)\n",
    "    \n",
    "    loss_function.to(device)\n",
    "    if strat_array:\n",
    "        kfold = StratifiedKFold(n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        split = kfold.split(dataset, strat_array)\n",
    "    else: \n",
    "        kfold = KFold(n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        split = kfold.split(dataset)\n",
    "\n",
    "    for fold, (train_ids, eval_ids) in enumerate(split):\n",
    "        if fold >= start_fold:\n",
    "            print(f'FOLD {fold}')\n",
    "            print('--------------------------------')\n",
    "            \n",
    "            \n",
    "            '''run = wandb.init(\n",
    "                name=f\"fold_{fold}\",\n",
    "                project=f\"{project_name}_fold_{fold}\",\n",
    "                config={ \n",
    "                         \"random_state\": random_state, \n",
    "                         \"shuffle\": shuffle,\n",
    "                         \"epochs\": epochs, \n",
    "                         \"learning_rate\": lr,\n",
    "                         \"batch_size\": batch_size,\n",
    "                         \"iters_to_accumulate\": iters_to_accumulate\n",
    "                        }\n",
    "            )'''\n",
    "\n",
    "            optimizer = MADGRAD(\n",
    "            model.parameters(),\n",
    "            lr = lr, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "        )\n",
    "\n",
    "            train_subsampler = torch.utils.data.Subset(dataset,  train_ids)\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                          train_subsampler, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle)\n",
    "\n",
    "            eval_subsampler = torch.utils.data.Subset(dataset,  eval_ids)\n",
    "            eval_loader = torch.utils.data.DataLoader(\n",
    "                          eval_subsampler,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle)\n",
    "            \n",
    "            total_steps = len(train_loader) * epochs \n",
    "\n",
    "            scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                                    num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                                    num_training_steps = total_steps)\n",
    "\n",
    "            mrrs = []\n",
    "\n",
    "            for epoch_i in range(0, epochs):\n",
    "                train_metrics = train_epoch(model, train_loader, loss_function, optimizer, scheduler, device)\n",
    "                eval_metrics = eval_epoch(model, eval_loader, loss_function, device)\n",
    "                \n",
    "                print(f\"EPOCH: {epoch_i}\")\n",
    "                print(train_metrics)\n",
    "                print(eval_metrics)\n",
    "                \n",
    "                #run.log(train_metrics)\n",
    "                #run.log(eval_metrics)\n",
    "                            \n",
    "            #run.finish()\n",
    "\n",
    "\n",
    "def single_model(model, \n",
    "                     dataset, \n",
    "                     loss_function, \n",
    "                     device=torch.device(\"cuda\"),\n",
    "                     random_state: int=69, \n",
    "                     shuffle=True,\n",
    "                     epochs: int=15, \n",
    "                     lr: float=1e-6,\n",
    "                     batch_size: int=32,\n",
    "                     start_epoch=0\n",
    "                     ):\n",
    "    random.seed(random_state),\n",
    "    np.random.seed(random_state)\n",
    "    torch.manual_seed(random_state)\n",
    "    torch.cuda.manual_seed_all(random_state)\n",
    "    \n",
    "    loss_function.to(device)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = MADGRAD(\n",
    "        model.parameters(),\n",
    "        lr = lr, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "    )\n",
    "    \n",
    "    fold_path = f'saves/resnet'\n",
    "    if not os.path.exists(fold_path):\n",
    "        os.mkdir(fold_path)\n",
    "        \n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "                    dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=shuffle\n",
    "    )\n",
    "    \n",
    "    total_steps = len(data_loader) * epochs \n",
    "\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "        if epoch_i >= start_epoch:\n",
    "            train_metrics = train_epoch(model, data_loader, loss_function, optimizer, scheduler, device)\n",
    "            epoch_path = fold_path+f'/epoch_{epoch_i}'\n",
    "            if not os.path.exists(epoch_path):\n",
    "                os.mkdir(epoch_path)\n",
    "            save_model(model, epoch_path)\n",
    "            print(\"EPOCH\", epoch_i)\n",
    "            print(train_metrics)\n",
    "            # eval_epoch(fold_model, eval_loader, loss_function, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e390562",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_array = []\n",
    "target_class = 0\n",
    "for folder in tqdm(os.listdir('data_ext/train')):\n",
    "    for _ in range(len(os.listdir('data_ext/train'+f'/{folder}'))):\n",
    "        strat_array.append(target_class)\n",
    "    print(folder)\n",
    "    target_class += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b172d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function=FocalLoss(weight=torch.tensor(correct_weights).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215f3b18",
   "metadata": {},
   "source": [
    "# ResNet50 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341d638f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m path_to_pretrain_resnet50 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel/model.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m resnet_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_pretrain_resnet50\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\len\\pythonproject1\\venv\\lib\\site-packages\\torch\\serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    769\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    773\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    774\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    775\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    776\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\users\\len\\pythonproject1\\venv\\lib\\site-packages\\torch\\serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\users\\len\\pythonproject1\\venv\\lib\\site-packages\\torch\\serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/model.pt'"
     ]
    }
   ],
   "source": [
    "path_to_pretrain_resnet50 = 'model/model.pt'\n",
    "resnet_weights = torch.load(path_to_pretrain_resnet50)\n",
    "backbone = torchvision.models.resnet50(weights = resnet_weights)\n",
    "effnet_best = ResNet(backbone, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aa1f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model(model = effnet_best, \n",
    "            dataset = train_dataset, \n",
    "            loss_function = loss_function, \n",
    "            device = torch.device(\"cuda\"),\n",
    "            random_state = 69, \n",
    "            shuffle = True,\n",
    "            epochs = 24, \n",
    "            lr = 1e-5,\n",
    "            batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_pretrain_resnet50 = 'model/model.pt'\n",
    "resnet_weights = torch.load(path_to_pretrain_resnet50)\n",
    "backbone = torchvision.models.resnet50(weights = resnet_weights)\n",
    "effnet_rs_30 = ResNet(backbone, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c4b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model(model = effnet_rs_30, \n",
    "            dataset = train_dataset, \n",
    "            loss_function = loss_function, \n",
    "            device = torch.device(\"cuda\"),\n",
    "            random_state = 30, \n",
    "            shuffle = True,\n",
    "            epochs = 24, \n",
    "            lr = 1e-5,\n",
    "            batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b529baff",
   "metadata": {},
   "source": [
    "# EfficientNet_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d13d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = torchvision.models.EfficientNet_B1_Weights.IMAGENET1K_V1\n",
    "effnet_b1 = torchvision.models.efficientnet_b1(weights=model_weights)\n",
    "effnet_b1.classifier[1] = nn.Linear(in_features = 1536, out_features =11, bias = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8b4055",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model(model = effnet_b1, \n",
    "            dataset = train_dataset, \n",
    "            loss_function = loss_function, \n",
    "            device = torch.device(\"cuda\"),\n",
    "            random_state = 69, \n",
    "            shuffle = True,\n",
    "            epochs = 40, \n",
    "            lr = 1e-5,\n",
    "            batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0699371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = torchvision.models.EfficientNet_B1_Weights.IMAGENET1K_V1\n",
    "effnet_b1_rs_40 = torchvision.models.efficientnet_b1(weights=model_weights)\n",
    "effnet_b1_rs_40.classifier[1] = nn.Linear(in_features = 1536, out_features =11, bias = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model(model = effnet_b1_rs_40, \n",
    "            dataset = train_dataset, \n",
    "            loss_function = loss_function, \n",
    "            device = torch.device(\"cuda\"),\n",
    "            random_state = 40, \n",
    "            shuffle = True,\n",
    "            epochs = 40, \n",
    "            lr = 1e-5,\n",
    "            batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a14bb",
   "metadata": {},
   "source": [
    "# EfficientNet b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef40e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = torchvision.models.EfficientNet_B3_Weights.IMAGENET1K_V1\n",
    "effnet_best = torchvision.models.efficientnet_b3(weights=model_weights)\n",
    "effnet_best.classifier[1] = nn.Linear(in_features = 1536, out_features =11, bias = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model(model = effnet_best, \n",
    "            dataset = train_dataset, \n",
    "            loss_function = loss_function, \n",
    "            device = torch.device(\"cuda\"),\n",
    "            random_state = 69, \n",
    "            shuffle = True,\n",
    "            epochs = 35, \n",
    "            lr = 1e-5,\n",
    "            batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = torchvision.models.EfficientNet_B3_Weights.IMAGENET1K_V1\n",
    "effnet_rs_30 = torchvision.models.efficientnet_b3(weights=model_weights)\n",
    "effnet_rs_30.classifier[1] = nn.Linear(in_features = 1536, out_features =11, bias = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model(model = effnet_best, \n",
    "            dataset = train_dataset, \n",
    "            loss_function = loss_function, \n",
    "            device = torch.device(\"cuda\"),\n",
    "            random_state = 30, \n",
    "            shuffle = True,\n",
    "            epochs = 35, \n",
    "            lr = 1e-5,\n",
    "            batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff578a25",
   "metadata": {},
   "source": [
    "# VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5842b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_tr(model, data_loader, loss_function, optimizer, scheduler, device, n_accumulated_grads=0):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    dl_size = len(data_loader)\n",
    "    \n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    batch_i = 0\n",
    "    steps_to_accumulate_grads = 0\n",
    "    for batch in tqdm(data_loader):\n",
    "        image, target = batch\n",
    "        image = image[\"pixel_values\"][0].to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()        \n",
    "        logits = model(image).logits\n",
    "                \n",
    "        preds.append(logits.argmax(dim=1))\n",
    "        targets.append(target)\n",
    "                \n",
    "        loss = loss_function(logits, target)\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    targets = torch.cat(targets, dim=0)\n",
    "    acc = (targets == preds).sum() / preds.shape[0]\n",
    "    f1 = f1_score(preds.cpu(), targets.cpu(), average='macro')\n",
    "    \n",
    "    metrics = {\n",
    "        \"Train Loss\": total_train_loss / dl_size,\n",
    "        \"Train Accuracy\": acc.item(),\n",
    "        \"Train F1\": f1.item()\n",
    "    }\n",
    "    \n",
    "    \n",
    "    return metrics\n",
    "    \n",
    "    \n",
    "def eval_epoch_tr(model, data_loader, loss_function, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    dl_size = len(data_loader)\n",
    "\n",
    "    \n",
    "    for batch in tqdm(data_loader):\n",
    "        image, target = batch\n",
    "        image = image[\"pixel_values\"][0].to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(image).logits\n",
    "            preds.append(logits.argmax(dim=1))\n",
    "            targets.append(target)\n",
    "        \n",
    "        loss = loss_function(logits, target)\n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    targets = torch.cat(targets, dim=0)\n",
    "    acc = (targets == preds).sum() / preds.shape[0]\n",
    "    f1 = f1_score(preds.cpu(), targets.cpu(), average='macro')\n",
    "    \n",
    "    metrics = {\n",
    "        \"Eval Loss\": total_train_loss / dl_size,\n",
    "        \"Eval Accuracy\": acc.item(),\n",
    "        \"Eval F1\": f1.item()\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(project_name,\n",
    "                     model, \n",
    "                     dataset, \n",
    "                     loss_function, \n",
    "                     strat_array=None,\n",
    "                     device=torch.device(\"cuda\"),\n",
    "                     random_state: int=69, \n",
    "                     shuffle: bool=True, \n",
    "                     n_folds: int=4, \n",
    "                     epochs: int=5, \n",
    "                     lr: float=1e-6,\n",
    "                     start_fold: int=0, \n",
    "                     batch_size: int=32,\n",
    "                     iters_to_accumulate=None,\n",
    "                     n_accumulated_grads: int = 0):\n",
    "    random.seed(random_state),\n",
    "    np.random.seed(random_state)\n",
    "    torch.manual_seed(random_state)\n",
    "    torch.cuda.manual_seed_all(random_state)\n",
    "    \n",
    "    loss_function.to(device)\n",
    "    if strat_array:\n",
    "        kfold = StratifiedKFold(n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        split = kfold.split(dataset, strat_array)\n",
    "    else: \n",
    "        kfold = KFold(n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        split = kfold.split(dataset)\n",
    "\n",
    "    for fold, (train_ids, eval_ids) in enumerate(split):\n",
    "        if fold >= start_fold:\n",
    "            print(f'FOLD {fold}')\n",
    "            print('--------------------------------')\n",
    "            \n",
    "            \n",
    "            '''run = wandb.init(\n",
    "                name=f\"fold_{fold}\",\n",
    "                project=f\"{project_name}_fold_{fold}\",\n",
    "                config={ \n",
    "                         \"random_state\": random_state, \n",
    "                         \"shuffle\": shuffle,\n",
    "                         \"epochs\": epochs, \n",
    "                         \"learning_rate\": lr,\n",
    "                         \"batch_size\": batch_size,\n",
    "                         \"iters_to_accumulate\": iters_to_accumulate\n",
    "                        }\n",
    "            )'''\n",
    "\n",
    "            optimizer = MADGRAD(\n",
    "            model.parameters(),\n",
    "            lr = lr, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "        )\n",
    "\n",
    "            train_subsampler = torch.utils.data.Subset(dataset,  train_ids)\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                          train_subsampler, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle)\n",
    "\n",
    "            eval_subsampler = torch.utils.data.Subset(dataset,  eval_ids)\n",
    "            eval_loader = torch.utils.data.DataLoader(\n",
    "                          eval_subsampler,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle)\n",
    "            \n",
    "            total_steps = len(train_loader) * epochs \n",
    "\n",
    "            scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                                    num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                                    num_training_steps = total_steps)\n",
    "\n",
    "            mrrs = []\n",
    "\n",
    "            for epoch_i in range(0, epochs):\n",
    "                train_metrics = train_epoch_tr(model, train_loader, loss_function, optimizer, scheduler, device)\n",
    "                eval_metrics = eval_epoch_tr(model, eval_loader, loss_function, device)\n",
    "                \n",
    "                print(f\"EPOCH: {epoch_i}\")\n",
    "                print(train_metrics)\n",
    "                print(eval_metrics)\n",
    "                \n",
    "                #run.log(train_metrics)\n",
    "                #run.log(eval_metrics)\n",
    "                            \n",
    "            #run.finish()\n",
    "\n",
    "\n",
    "def single_model_tr(model, \n",
    "                     dataset, \n",
    "                     loss_function, \n",
    "                     device=torch.device(\"cuda\"),\n",
    "                     random_state: int=69, \n",
    "                     shuffle=True,\n",
    "                     epochs: int=15, \n",
    "                     lr: float=1e-6,\n",
    "                     batch_size: int=32,\n",
    "                     start_epoch=0\n",
    "                     ):\n",
    "    random.seed(random_state),\n",
    "    np.random.seed(random_state)\n",
    "    torch.manual_seed(random_state)\n",
    "    torch.cuda.manual_seed_all(random_state)\n",
    "    \n",
    "    loss_function.to(device)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = MADGRAD(\n",
    "        model.parameters(),\n",
    "        lr = lr, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "    )\n",
    "    \n",
    "    fold_path = f'vit'\n",
    "    if not os.path.exists(fold_path):\n",
    "        os.mkdir(fold_path)\n",
    "        \n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "                    dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=shuffle\n",
    "    )\n",
    "    \n",
    "    total_steps = len(data_loader) * epochs \n",
    "\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "        if epoch_i >= start_epoch:\n",
    "            train_metrics = train_epoch_tr(model, data_loader, loss_function, optimizer, scheduler, device)\n",
    "            epoch_path = fold_path+f'/epoch_{epoch_i + 9}'\n",
    "            if not os.path.exists(epoch_path):\n",
    "                os.mkdir(epoch_path)\n",
    "            save_model(model, epoch_path)\n",
    "            print(\"EPOCH\", epoch_i)\n",
    "            print(train_metrics)\n",
    "            # eval_epoch(fold_model, eval_loader, loss_function, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d250f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = AutoFeatureExtractor.from_pretrained(\"therealcyberlord/stanford-car-vit-patch16\")\n",
    "transformer = AutoModelForImageClassification.from_pretrained(\"therealcyberlord/stanford-car-vit-patch16\")\n",
    "transformer.classifier = nn.Linear(768, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc87292",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model_tr(model = transformer, \n",
    "             dataset = train_dataset, \n",
    "             loss_function = loss_function, \n",
    "             device = torch.device(\"cuda\"),\n",
    "             random_state = 69, \n",
    "             shuffle = True,\n",
    "             epochs = 15, \n",
    "             lr = 1e-5,\n",
    "             batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad34c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = AutoFeatureExtractor.from_pretrained(\"therealcyberlord/stanford-car-vit-patch16\")\n",
    "transformer_1337 = AutoModelForImageClassification.from_pretrained(\"therealcyberlord/stanford-car-vit-patch16\")\n",
    "transformer_1337.classifier = nn.Linear(768, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2d0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model_tr(model = transformer_1337, \n",
    "             dataset = train_dataset, \n",
    "             loss_function = loss_function, \n",
    "             device = torch.device(\"cuda\"),\n",
    "             random_state = 1337, \n",
    "             shuffle = True,\n",
    "             epochs = 15, \n",
    "             lr = 1e-5,\n",
    "             batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06837b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = AutoFeatureExtractor.from_pretrained(\"therealcyberlord/stanford-car-vit-patch16\")\n",
    "transformer_666 = AutoModelForImageClassification.from_pretrained(\"therealcyberlord/stanford-car-vit-patch16\")\n",
    "transformer_666.classifier = nn.Linear(768, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b232d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model_tr(model = transformer_666, \n",
    "             dataset = train_dataset, \n",
    "             loss_function = loss_function, \n",
    "             device = torch.device(\"cuda\"),\n",
    "             random_state = 666, \n",
    "             shuffle = True,\n",
    "             epochs = 15, \n",
    "             lr = 1e-5,\n",
    "             batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f051dd3",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa40bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    resnet_best, \n",
    "    resnet_rs_30,\n",
    "    effnet_best,\n",
    "    effnet_rs_30,\n",
    "    effnet_b1,\n",
    "    effnet_b1_rs_40,\n",
    "]\n",
    "transformers = [\n",
    "    transformer,\n",
    "    transformer_1337,\n",
    "    transformer_666,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559848d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms=torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize(size=(256,256)),\n",
    "    torchvision.transforms.Lambda(lambda a: a / 255),\n",
    "])\n",
    "\n",
    "transformer_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize(size=(224,224)),\n",
    "    torchvision.transforms.Lambda(lambda a: extractor(a)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daeb2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_blending(models, transformers, root, device, test_transform, trsf_transforms):\n",
    "    for model in models:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "    \n",
    "    transformer.eval()\n",
    "    transformer.to(device)\n",
    "    preds = []\n",
    "    img_files = sorted(os.listdir(root), key=lambda x: int(x.split(\".\")[0]))\n",
    "    print(img_files)\n",
    "    for img_file in tqdm(img_files):\n",
    "        img_rgb = Image.open(root + img_file)\n",
    "        image = test_transform(img_rgb).to(device)\n",
    "        image_trsf = trsf_transforms(img_rgb)\n",
    "        image_trsf = torch.tensor(image_trsf[\"pixel_values\"][0]).unsqueeze(dim=0).to(device)\n",
    "        pred = torch.zeros(1, 11)\n",
    "        with torch.no_grad():\n",
    "            for model in models:\n",
    "                pred += nn.Softmax(dim = 1)(model(image.unsqueeze(dim=0)).cpu())\n",
    "            for trsf in transformers:\n",
    "                pred += nn.Softmax(dim = 1)(trsf(image_trsf).logits.cpu())\n",
    "            pred /= len(models) + len(transformers)\n",
    "            preds.append(pred.argmax(dim = 1).item())\n",
    "    return pd.Series(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a971165",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_blend = predict_blending(models = models, transformers = transformers, device = 'cuda',\n",
    "                              root ='data_ext/public_test/', test_transform = test_transforms, \n",
    "                              trsf_transforms=transformer_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34673d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_blend = pred_blend.apply(lambda x: train_dataset.classes[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac16ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_blend.to_csv(\"final_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
